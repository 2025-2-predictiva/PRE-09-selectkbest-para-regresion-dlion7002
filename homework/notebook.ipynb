{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25df0f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Función para cargar y preparar los datos del dataset auto_mpg.\n",
    "    \n",
    "    Esta función realiza las siguientes operaciones:\n",
    "    1. Carga el dataset desde un archivo CSV\n",
    "    2. Limpia los datos eliminando valores nulos\n",
    "    3. Mapea valores numéricos de origen a nombres de países\n",
    "    4. Separa la variable objetivo (MPG) de las características\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (x, y) donde x son las características y y es la variable objetivo\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    # Cargar el dataset de consumo de combustible de automóviles desde el archivo CSV\n",
    "    dataset = pd.read_csv(\"../files/input/auto_mpg.csv\")\n",
    "    \n",
    "    # Eliminar todas las filas que contengan valores nulos (NaN)\n",
    "    # Esto es importante para evitar errores en el entrenamiento del modelo\n",
    "    dataset = dataset.dropna()\n",
    "    \n",
    "    # Mapear los valores numéricos de la columna \"Origin\" a nombres de países\n",
    "    # 1 = USA, 2 = Europe, 3 = Japan\n",
    "    # Esto convierte una variable numérica en categórica más interpretable\n",
    "    dataset[\"Origin\"] = dataset[\"Origin\"].map(\n",
    "        {1: \"USA\", 2: \"Europe\", 3: \"Japan\"},\n",
    "    )\n",
    "    \n",
    "    # Extraer la variable objetivo (MPG - Miles Per Gallon)\n",
    "    # pop() elimina la columna del dataset y la retorna\n",
    "    y = dataset.pop(\"MPG\")\n",
    "    \n",
    "    # Crear una copia del dataset sin la variable objetivo\n",
    "    # Estas serán nuestras características (features) para el modelo\n",
    "    x = dataset.copy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b790724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_split(x, y):\n",
    "    \"\"\"\n",
    "    Función para dividir los datos en conjuntos de entrenamiento y prueba.\n",
    "    \n",
    "    Esta función separa los datos en dos conjuntos:\n",
    "    - Entrenamiento (75%): para entrenar el modelo\n",
    "    - Prueba (25%): para evaluar el rendimiento del modelo\n",
    "    \n",
    "    Args:\n",
    "        x: Características (features)\n",
    "        y: Variable objetivo (target)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (x_train, x_test, y_train, y_test) conjuntos de entrenamiento y prueba\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento (75%) y prueba (25%)\n",
    "    # test_size=0.25 significa que el 25% de los datos se usarán para prueba\n",
    "    # random_state=123456 asegura que la división sea reproducible\n",
    "    # (siempre obtendremos la misma división aleatoria)\n",
    "    (x_train, x_test, y_train, y_test) = train_test_split(\n",
    "        x,                    # Características de entrada\n",
    "        y,                    # Variable objetivo\n",
    "        test_size=0.25,       # 25% para prueba, 75% para entrenamiento\n",
    "        random_state=123456,  # Semilla para reproducibilidad\n",
    "    )\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29fc887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(estimator):\n",
    "    \"\"\"\n",
    "    Función para crear un pipeline de procesamiento de datos y modelado.\n",
    "    \n",
    "    El pipeline consta de tres pasos principales:\n",
    "    1. Transformación de datos (codificación y escalado)\n",
    "    2. Selección de características (SelectKBest)\n",
    "    3. Modelo de predicción (estimador)\n",
    "    \n",
    "    Args:\n",
    "        estimator: El modelo de machine learning a usar (ej: LinearRegression, MLPRegressor)\n",
    "    \n",
    "    Returns:\n",
    "        Pipeline: Pipeline completo listo para entrenar\n",
    "    \"\"\"\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.feature_selection import SelectKBest, f_regression\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "    # PASO 1: Configurar el transformador de columnas\n",
    "    # Esto maneja diferentes tipos de datos de manera apropiada\n",
    "    transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            # OneHotEncoder para la variable categórica \"Origin\"\n",
    "            # dtype=\"int\" convierte los valores booleanos a enteros (0, 1)\n",
    "            # Esto crea variables dummy para USA, Europe, Japan\n",
    "            (\"ohe\", OneHotEncoder(dtype=\"int\"), [\"Origin\"]),\n",
    "        ],\n",
    "        # remainder=StandardScaler() aplica normalización estándar \n",
    "        # a todas las demás columnas numéricas\n",
    "        # Esto centra los datos en 0 y los escala a desviación estándar de 1\n",
    "        remainder=StandardScaler(),\n",
    "    )\n",
    "\n",
    "    # PASO 2: Configurar la selección de características\n",
    "    # SelectKBest selecciona las k mejores características basándose en una función de puntuación\n",
    "    # f_regression es la función de puntuación para problemas de regresión\n",
    "    # Evalúa la correlación lineal entre cada característica y la variable objetivo\n",
    "    selectkbest = SelectKBest(score_func=f_regression)\n",
    "\n",
    "    # PASO 3: Crear el pipeline completo\n",
    "    # Los pasos se ejecutan secuencialmente en el orden especificado\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            # 1. Transformar datos (codificación + normalización)\n",
    "            (\"tranformer\", transformer),\n",
    "            # 2. Seleccionar las mejores características\n",
    "            (\"selectkbest\", selectkbest),\n",
    "            # 3. Aplicar el modelo de predicción\n",
    "            (\"estimator\", estimator),\n",
    "        ],\n",
    "        verbose=False,  # No mostrar información detallada durante la ejecución\n",
    "    )\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73448488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid_search(estimator, param_grid, cv=5):\n",
    "    \"\"\"\n",
    "    Función para crear un GridSearchCV que encuentra los mejores hiperparámetros.\n",
    "    \n",
    "    GridSearchCV prueba todas las combinaciones posibles de parámetros\n",
    "    especificados en param_grid y selecciona la mejor combinación\n",
    "    basándose en validación cruzada.\n",
    "    \n",
    "    Args:\n",
    "        estimator: El pipeline o modelo a optimizar\n",
    "        param_grid: Diccionario con los parámetros a probar\n",
    "        cv: Número de folds para validación cruzada (default=5)\n",
    "    \n",
    "    Returns:\n",
    "        GridSearchCV: Objeto configurado para búsqueda de hiperparámetros\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    # Crear el objeto GridSearchCV para búsqueda exhaustiva de hiperparámetros\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator,           # El pipeline/modelo a optimizar\n",
    "        param_grid=param_grid,         # Diccionario con parámetros a probar\n",
    "        cv=cv,                         # Validación cruzada de 5 folds por defecto\n",
    "        # Métrica de evaluación: Error Absoluto Medio negativo\n",
    "        # Se usa negativo porque GridSearch busca maximizar, pero queremos minimizar el error\n",
    "        scoring='neg_mean_absolute_error',\n",
    "    )\n",
    "\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0cfbf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_estimator(estimator):\n",
    "    \"\"\"\n",
    "    Función para guardar un modelo entrenado en disco.\n",
    "    \n",
    "    Utiliza pickle para serializar el objeto del modelo y guardarlo\n",
    "    en un archivo binario. Esto permite reutilizar el modelo entrenado\n",
    "    sin necesidad de volver a entrenarlo.\n",
    "    \n",
    "    Args:\n",
    "        estimator: El modelo entrenado a guardar\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "\n",
    "    # Abrir archivo en modo binario de escritura (\"wb\")\n",
    "    # El modelo se serializa usando pickle y se guarda como \"estimator.pickle\"\n",
    "    with open(\"estimator.pickle\", \"wb\") as file:\n",
    "        # pickle.dump() serializa el objeto estimator y lo escribe al archivo\n",
    "        # Esto preserva completamente el estado del modelo entrenado\n",
    "        pickle.dump(estimator, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17252538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_estimator():\n",
    "    \"\"\"\n",
    "    Función para cargar un modelo previamente guardado desde disco.\n",
    "    \n",
    "    Busca el archivo \"estimator.pickle\" y lo carga si existe.\n",
    "    Si no existe, retorna None.\n",
    "    \n",
    "    Returns:\n",
    "        estimator or None: El modelo cargado o None si no existe el archivo\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pickle\n",
    "\n",
    "    # Verificar si existe el archivo del modelo guardado\n",
    "    # Si no existe, significa que no hay un modelo previo guardado\n",
    "    if not os.path.exists(\"estimator.pickle\"):\n",
    "        return None\n",
    "    \n",
    "    # Abrir el archivo en modo binario de lectura (\"rb\")\n",
    "    with open(\"estimator.pickle\", \"rb\") as file:\n",
    "        # pickle.load() deserializa el objeto desde el archivo\n",
    "        # Esto restaura completamente el modelo con todos sus parámetros entrenados\n",
    "        estimator = pickle.load(file)\n",
    "\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4c91db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Documents\\AAprogramación general\\AANacho\\Predictiva\\PRE-09-selectkbest-para-regresion-dlion7002\\.venv\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\Documents\\AAprogramación general\\AANacho\\Predictiva\\PRE-09-selectkbest-para-regresion-dlion7002\\.venv\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\Documents\\AAprogramación general\\AANacho\\Predictiva\\PRE-09-selectkbest-para-regresion-dlion7002\\.venv\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\Documents\\AAprogramación general\\AANacho\\Predictiva\\PRE-09-selectkbest-para-regresion-dlion7002\\.venv\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator SelectKBest from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\Documents\\AAprogramación general\\AANacho\\Predictiva\\PRE-09-selectkbest-para-regresion-dlion7002\\.venv\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LinearRegression from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\Documents\\AAprogramación general\\AANacho\\Predictiva\\PRE-09-selectkbest-para-regresion-dlion7002\\.venv\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\Documents\\AAprogramación general\\AANacho\\Predictiva\\PRE-09-selectkbest-para-regresion-dlion7002\\.venv\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator GridSearchCV from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def train_linear_regression():\n",
    "    \"\"\"\n",
    "    Función principal para entrenar un modelo de regresión lineal.\n",
    "    \n",
    "    Esta función implementa un flujo completo de machine learning:\n",
    "    1. Carga los datos\n",
    "    2. Divide en entrenamiento/prueba\n",
    "    3. Crea pipeline con selección de características\n",
    "    4. Busca los mejores hiperparámetros\n",
    "    5. Compara con modelo previo guardado\n",
    "    6. Guarda el mejor modelo\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    \n",
    "\n",
    "    # PASO 1: Cargar y preparar los datos\n",
    "    data, target = load_data()\n",
    "\n",
    "    # PASO 2: Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    x_train, x_test, y_train, y_test = make_train_test_split(\n",
    "        x=data,\n",
    "        y=target,\n",
    "    )\n",
    "\n",
    "    # PASO 3: Crear el pipeline con LinearRegression como estimador\n",
    "    # El pipeline incluye: transformación -> selección de características -> regresión lineal\n",
    "    pipeline = make_pipeline(\n",
    "        estimator=LinearRegression(),\n",
    "    )\n",
    "\n",
    "    # PASO 4: Configurar búsqueda de hiperparámetros\n",
    "    # Probará diferentes valores de k (número de características a seleccionar)\n",
    "    # desde 1 hasta el total de características disponibles\n",
    "    estimator = make_grid_search(\n",
    "        estimator=pipeline,\n",
    "        param_grid={\n",
    "            # Probar todos los valores posibles de k para SelectKBest\n",
    "            \"selectkbest__k\": range(1, len(x_train.columns) + 1),\n",
    "        },\n",
    "        cv=5,  # Validación cruzada de 5 folds\n",
    "    )\n",
    "\n",
    "    # PASO 5: Entrenar el modelo con búsqueda de hiperparámetros\n",
    "    # GridSearchCV probará todas las combinaciones y encontrará la mejor\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    # PASO 6: Comparar con modelo previamente guardado (si existe)\n",
    "    best_estimator = load_estimator()\n",
    "\n",
    "    if best_estimator is not None:\n",
    "        # Calcular el error del modelo guardado previamente\n",
    "        saved_mae = mean_absolute_error(\n",
    "            y_true=y_test, y_pred=best_estimator.predict(x_test)\n",
    "        )\n",
    "\n",
    "        # Calcular el error del modelo recién entrenado\n",
    "        current_mae = mean_absolute_error(\n",
    "            y_true=y_test, y_pred=estimator.predict(x_test)\n",
    "        )\n",
    "\n",
    "        # Si el modelo guardado es mejor, usarlo en lugar del nuevo\n",
    "        # Esto implementa una forma de \"early stopping\" o conservación del mejor modelo\n",
    "        if saved_mae < current_mae:\n",
    "            estimator = best_estimator\n",
    "\n",
    "    # PASO 7: Guardar el mejor modelo (nuevo o el previo si era mejor)\n",
    "    save_estimator(estimator)\n",
    "\n",
    "\n",
    "# Ejecutar el entrenamiento de regresión lineal\n",
    "train_linear_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e16fd4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Función para calcular métricas de evaluación para modelos de regresión.\n",
    "    \n",
    "    Calcula tres métricas principales para evaluar el rendimiento:\n",
    "    - MSE: Error Cuadrático Medio\n",
    "    - MAE: Error Absoluto Medio  \n",
    "    - R²: Coeficiente de Determinación\n",
    "    \n",
    "    Args:\n",
    "        y_true: Valores reales de la variable objetivo\n",
    "        y_pred: Valores predichos por el modelo\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (mse, mae, r2) métricas calculadas\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "    # MSE (Mean Squared Error): Promedio de los errores al cuadrado\n",
    "    # Penaliza más los errores grandes debido al cuadrado\n",
    "    # Valores más bajos indican mejor rendimiento\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "    # MAE (Mean Absolute Error): Promedio de los valores absolutos de los errores\n",
    "    # Más robusto a outliers que MSE\n",
    "    # Interpretación directa: error promedio en las mismas unidades que la variable objetivo\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # R² (R-squared): Coeficiente de determinación\n",
    "    # Indica qué proporción de la varianza es explicada por el modelo\n",
    "    # Rango: (-∞, 1], donde 1 es perfecto y 0 significa que el modelo no es mejor que la media\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2a40cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(estimator, mse, mae, r2):\n",
    "    \"\"\"\n",
    "    Función para mostrar un reporte formateado de las métricas del modelo.\n",
    "    \n",
    "    Imprime de manera organizada:\n",
    "    - El tipo de estimador/modelo usado\n",
    "    - Las tres métricas principales de evaluación\n",
    "    \n",
    "    Args:\n",
    "        estimator: El modelo evaluado\n",
    "        mse: Error Cuadrático Medio\n",
    "        mae: Error Absoluto Medio\n",
    "        r2: Coeficiente de Determinación (R²)\n",
    "    \"\"\"\n",
    "    # Mostrar el tipo de estimador (ej: LinearRegression, MLPRegressor, etc.)\n",
    "    print(estimator, \":\", sep=\"\")\n",
    "    \n",
    "    # Mostrar las métricas con formato consistente\n",
    "    print(f\"  MSE: {mse}\")  # Error Cuadrático Medio\n",
    "    print(f\"  MAE: {mae}\")  # Error Absoluto Medio  \n",
    "    print(f\"   R2: {r2}\")   # Coeficiente de Determinación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d040e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('tranformer',\n",
      "                 ColumnTransformer(remainder=StandardScaler(),\n",
      "                                   transformers=[('ohe',\n",
      "                                                  OneHotEncoder(dtype='int'),\n",
      "                                                  ['Origin'])])),\n",
      "                ('selectkbest',\n",
      "                 SelectKBest(k=6,\n",
      "                             score_func=<function f_regression at 0x000001F1F9ACC2C0>)),\n",
      "                ('estimator', LinearRegression())]):\n",
      "  MSE: 11.177256954645403\n",
      "  MAE: 2.524517976430189\n",
      "   R2: 0.8089190863428402\n"
     ]
    }
   ],
   "source": [
    "def check_estimator():\n",
    "    \"\"\"\n",
    "    Función para evaluar el rendimiento del modelo guardado.\n",
    "    \n",
    "    Esta función:\n",
    "    1. Carga los datos de prueba\n",
    "    2. Carga el modelo guardado\n",
    "    3. Hace predicciones\n",
    "    4. Calcula métricas de evaluación\n",
    "    5. Muestra un reporte del rendimiento\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "    # PASO 1: Cargar y dividir los datos de la misma manera que en entrenamiento\n",
    "    # Es crucial usar la misma división para obtener resultados comparables\n",
    "    data, target = load_data()\n",
    "\n",
    "    x_train, x_test, y_train_true, y_test_true = make_train_test_split(\n",
    "        x=data,\n",
    "        y=target,\n",
    "    )\n",
    "\n",
    "    # PASO 2: Cargar el modelo previamente entrenado y guardado\n",
    "    estimator = load_estimator()\n",
    "\n",
    "    # PASO 3: Calcular métricas de evaluación\n",
    "    # Usar el conjunto de prueba para evaluar el rendimiento real del modelo\n",
    "    mse, mae, r2 = eval_metrics(\n",
    "        y_test_true,                    # Valores reales del conjunto de prueba\n",
    "        estimator.predict(x_test),      # Predicciones del modelo en el conjunto de prueba\n",
    "    )\n",
    "\n",
    "    # PASO 4: Mostrar reporte del rendimiento\n",
    "    # estimator.best_estimator_ contiene el mejor modelo encontrado por GridSearchCV\n",
    "    report(estimator.best_estimator_, mse, mae, r2)\n",
    "\n",
    "\n",
    "# Ejecutar la evaluación del modelo guardado\n",
    "check_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp_regressor():\n",
    "    \"\"\"\n",
    "    Función para entrenar un modelo de Red Neuronal Multicapa (MLP) para regresión.\n",
    "    \n",
    "    Similar a train_linear_regression(), pero usa MLPRegressor y busca\n",
    "    hiperparámetros adicionales específicos de redes neuronales:\n",
    "    - Número de características (k)\n",
    "    - Tamaño de capas ocultas\n",
    "    - Tasa de aprendizaje\n",
    "    \n",
    "    MLP es más complejo que regresión lineal y puede capturar relaciones no lineales.\n",
    "    \"\"\"\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "    # PASO 1: Cargar y preparar los datos (igual que en regresión lineal)\n",
    "    data, target = load_data()\n",
    "\n",
    "    # PASO 2: Dividir en entrenamiento y prueba\n",
    "    x_train, x_test, y_train, y_test = make_train_test_split(\n",
    "        x=data,\n",
    "        y=target,\n",
    "    )\n",
    "\n",
    "    # PASO 3: Crear pipeline con MLPRegressor\n",
    "    # max_iter=30000: número máximo de iteraciones para convergencia\n",
    "    # MLPs requieren más iteraciones que modelos lineales\n",
    "    pipeline = make_pipeline(\n",
    "        estimator=MLPRegressor(max_iter=30000),\n",
    "    )\n",
    "\n",
    "    # PASO 4: Configurar búsqueda exhaustiva de hiperparámetros para redes neuronales\n",
    "    estimator = make_grid_search(\n",
    "        estimator=pipeline,\n",
    "        param_grid={\n",
    "            # Número de características a seleccionar (igual que regresión lineal)\n",
    "            \"selectkbest__k\": range(1, len(x_train.columns) + 1),\n",
    "            \n",
    "            # Arquitectura de la red: probar redes con 1 a 10 neuronas en una capa oculta\n",
    "            # (n,) significa una sola capa oculta con n neuronas\n",
    "            \"estimator__hidden_layer_sizes\": [(n,) for n in range(1, 11)],\n",
    "            \n",
    "            # Algoritmo de optimización: Adam es eficiente para la mayoría de problemas\n",
    "            \"estimator__solver\": [\"adam\"],\n",
    "            \n",
    "            # Tasa de aprendizaje: controla qué tan grandes son los pasos de actualización\n",
    "            # Valores más pequeños = aprendizaje más lento pero potencialmente más estable\n",
    "            \"estimator__learning_rate_init\": [0.01, 0.001, 0.0001],\n",
    "        },\n",
    "        cv=5,  # Validación cruzada de 5 folds\n",
    "    )\n",
    "\n",
    "    # PASO 5: Entrenar con búsqueda de hiperparámetros\n",
    "    # Esto puede tomar mucho tiempo debido a la complejidad del espacio de búsqueda\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    # PASO 6: Comparar con el mejor modelo previo (igual lógica que regresión lineal)\n",
    "    best_estimator = load_estimator()\n",
    "\n",
    "    if best_estimator is not None:\n",
    "        # Evaluar modelo guardado previamente\n",
    "        saved_mae = mean_absolute_error(\n",
    "            y_true=y_test, y_pred=best_estimator.predict(x_test)\n",
    "        )\n",
    "\n",
    "        # Evaluar modelo recién entrenado\n",
    "        current_mae = mean_absolute_error(\n",
    "            y_true=y_test, y_pred=estimator.predict(x_test)\n",
    "        )\n",
    "\n",
    "        # Conservar el mejor modelo (puede ser el anterior si era superior)\n",
    "        if saved_mae < current_mae:\n",
    "            estimator = best_estimator\n",
    "\n",
    "    # PASO 7: Guardar el mejor modelo\n",
    "    save_estimator(estimator)\n",
    "\n",
    "\n",
    "# Ejecutar entrenamiento de red neuronal\n",
    "train_mlp_regressor()\n",
    "\n",
    "# Evaluar el modelo final (que puede ser regresión lineal o MLP, el que tenga mejor rendimiento)\n",
    "check_estimator()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
